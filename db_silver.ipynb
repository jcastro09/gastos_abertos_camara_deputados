{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deputadosDespesas\n",
      "Leitura do deputadosDespesas.parquet concluída\n",
      "valorDocumento\n",
      "transformacao concluida com sucessso\n",
      "valorGlosa\n",
      "transformacao concluida com sucessso\n",
      "valorLiquido\n",
      "transformacao concluida com sucessso\n",
      "Tratamento do deputadosDespesas.parquet concluído\n",
      "Arquivo Parquet 'deputadosDespesas.parquet' enviado com sucesso para o Azure Blob Storage.\n",
      "Envio do deputadosDespesas.parquet concluído\n",
      "deputados\n",
      "Leitura do deputados.parquet concluída\n",
      "Tratamento do deputados.parquet concluído\n",
      "Arquivo Parquet 'deputados.parquet' enviado com sucesso para o Azure Blob Storage.\n",
      "Envio do deputados.parquet concluído\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "import io\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Credenciais\n",
    "account_name = 'uvabr'\n",
    "account_key = os.environ['ACCOUNT_KEY']\n",
    "container_name_read = 'bronze'\n",
    "container_name_send = 'silver'\n",
    "\n",
    "endpoints = [\n",
    "    \"deputadosDespesas\",\n",
    "#    \"proposicoes\",\n",
    "#    \"proposicoesTemas\",\n",
    "#    \"proposicoesAutores\",\n",
    "#    \"frentes\",\n",
    "#    \"frentesDeputados\",\n",
    "#    \"grupos\",\n",
    "#    \"gruposMembros\",\n",
    "#    \"gruposHistorico\",\n",
    "#    \"legislaturas\",\n",
    "#    \"legislaturasMesas\",\n",
    "#    \"orgaos\",\n",
    "#    \"orgaosDeputados\",\n",
    "    \"deputados\",\n",
    "#    \"deputadosOcupacoes\",\n",
    "#    \"deputadosProfissoes\",\n",
    "#    \"eventos\",\n",
    "#    \"eventosOrgaos\",\n",
    "#    \"eventosRequerimentos\",\n",
    "#    \"votacoes\",\n",
    "#    \"votacoesOrientacoes\",\n",
    "#    \"votacoesVotos\",\n",
    "#    \"votacoesObjetos\",\n",
    "#    \"votacoesProposicoes\",\n",
    "#    \"funcionarios\",\n",
    "#    \"licitacoes\",\n",
    "#    \"licitacoesContratos\",\n",
    "#    \"licitacoesItens\",\n",
    "#    \"licitacoesPedidos\",\n",
    "#    \"licitacoesPropostas\",\n",
    "#    \"tecadTermos\",\n",
    "#    \"tecadCategorias\",\n",
    "#    \"deputadosCompleto\",\n",
    "#    \"partidosCompleto\"\n",
    "]\n",
    "\n",
    "def ler_parquet_azure(account_name, account_key, container_name_read, file_name):\n",
    "    # Conecte-se ao serviço de armazenamento de blob\n",
    "    connect_str = f\"DefaultEndpointsProtocol=https;AccountName={account_name};AccountKey={account_key};EndpointSuffix=core.windows.net\"\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
    "\n",
    "    # Acesse o contêiner\n",
    "    container_client = blob_service_client.get_container_client(container_name_read)\n",
    "\n",
    "    # Baixe o blob do Azure Blob Storage\n",
    "    blob_client = container_client.get_blob_client(file_name)\n",
    "    blob_data = blob_client.download_blob()\n",
    "    blob_stream = io.BytesIO()\n",
    "    blob_stream.write(blob_data.readall())\n",
    "\n",
    "    # Leia o arquivo Parquet usando pyarrow\n",
    "    parquet_table = pq.read_table(blob_stream)\n",
    "\n",
    "    # Converta para DataFrame do Pandas\n",
    "    df = parquet_table.to_pandas()\n",
    "\n",
    "    return df\n",
    "\n",
    "def enviar_parquet_azure(account_name, account_key, container_name_send, file_name, dataframe):\n",
    "    # Conecte-se ao serviço de armazenamento de blob\n",
    "    connect_str = f\"DefaultEndpointsProtocol=https;AccountName={account_name};AccountKey={account_key};EndpointSuffix=core.windows.net\"\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
    "\n",
    "    # Acesse o contêiner\n",
    "    container_client = blob_service_client.get_container_client(container_name_send)\n",
    "\n",
    "    # Converta DataFrame para tabela Parquet\n",
    "    table = pa.Table.from_pandas(dataframe)\n",
    "\n",
    "    # Crie um buffer de memória para escrever os dados Parquet\n",
    "    parquet_buffer = io.BytesIO()\n",
    "    pq.write_table(table, parquet_buffer)\n",
    "\n",
    "    # Envie os dados para o Azure Blob Storage\n",
    "    blob_client = container_client.get_blob_client(file_name)\n",
    "    blob_client.upload_blob(parquet_buffer.getvalue(), overwrite=True)\n",
    "\n",
    "    print(f\"Arquivo Parquet '{file_name}' enviado com sucesso para o Azure Blob Storage.\")\n",
    "\n",
    "def criar_coluna_uri(dataframe, endpoint):\n",
    "    # Padronize o prefixo da coluna com base no endpoint\n",
    "    prefixo_coluna = \"uri_\" + endpoint\n",
    "\n",
    "    # Para cada linha no DataFrame\n",
    "    for indice, linha in dataframe.iterrows():\n",
    "        # Para cada coluna no DataFrame\n",
    "        for coluna, valor in linha.items():\n",
    "            # Se a coluna contiver \"uri\" em algum lugar no nome\n",
    "            if \"uri\" in coluna.lower():\n",
    "                # Use expressão regular para extrair o ID do URI\n",
    "                match = re.search(r'(\\d+)$', str(valor))\n",
    "\n",
    "                # Se houver uma correspondência na expressão regular\n",
    "                if match:\n",
    "                    # Crie uma nova coluna com o prefixo apropriado e atribua o valor extraído\n",
    "                    nova_coluna = prefixo_coluna + \"_\" + coluna.replace(\"uri\", \"\").strip(\"_\")\n",
    "                    # Remova o sublinhado no final do nome da coluna, se houver\n",
    "                    nova_coluna = nova_coluna.rstrip('_')\n",
    "                    dataframe.at[indice, nova_coluna] = match.group(1)\n",
    "    return dataframe        \n",
    "\n",
    "def transformar_coluna_data(dfdata):\n",
    "    for coluna in dfdata.columns:\n",
    "        if 'data' in coluna.lower():  # Verifica se o nome da coluna contém 'data'\n",
    "            try:\n",
    "                dfdata[coluna] = dfdata[coluna].apply(lambda x: '' if (x == None or x < ('1800-01-01') or x > ('2099-12-31') ) else x)\n",
    "                dfdata[coluna] = pd.to_datetime(dfdata[coluna])  # Converte para datetime\n",
    "            except ValueError:\n",
    "                print(f\"Erro ao converter coluna {coluna} para datetime.\")\n",
    "    return dfdata\n",
    "\n",
    "def transform_id_cod_to_string(df):\n",
    "    for coluna in df.columns:\n",
    "        if 'id' in coluna.lower() or 'cod' in coluna.lower():\n",
    "            df[coluna] = df[coluna].astype(str)\n",
    "    return df\n",
    "\n",
    "def transformar_valores(df):\n",
    "    for column in df.columns:\n",
    "        if 'url' not in column.lower():  # Verifica se \"url\" NÃO está no nome da coluna\n",
    "            if df[column].dtype != 'datetime64[ns]' and df[column].dtype != 'float64':\n",
    "                df[column] = df[column].replace(['', '<NA>', '[]', pd.NaT, np.nan, None], 'N/A')\n",
    "            elif df[column].dtype == 'float64':\n",
    "                print(\"nada funciona aqui\")\n",
    "                df[column] = df[column].fillna('N/A').astype('str')\n",
    "    return df\n",
    "\n",
    "def transformar_valores_float(df):\n",
    "    for column in df.columns:\n",
    "        if 'valor' in column.lower():\n",
    "            print(column)# Verifica se \"url\" NÃO está no nome da coluna\n",
    "            if df[column].dtype == 'object' or df[column].dtype == 'string':\n",
    "                df[column] = df[column].astype(float)\n",
    "                print(\"transformacao concluida com sucessso\")  \n",
    "            else:\n",
    "                print(\"Deu ruim\")             \n",
    "    return df\n",
    "\n",
    "def converter_float64_to_int(df):\n",
    "    float_cols = df.select_dtypes(include=['float64']).columns\n",
    "    df[float_cols] = df[float_cols].astype('int')\n",
    "    return df\n",
    "\n",
    "\n",
    "#tratamento direto\n",
    "\n",
    "#tratamento global\n",
    "def processar_endpoints(account_name, account_key, container_name_read, container_name_send, endpoints):\n",
    "    for endpoint in endpoints:\n",
    "        print(endpoint)\n",
    "        df = ler_parquet_azure(account_name, account_key, container_name_read, f'{endpoint}.parquet')\n",
    "        print(f\"Leitura do {endpoint}.parquet concluída\")\n",
    "        df = criar_coluna_uri(df, endpoint)\n",
    "        df = transformar_coluna_data(df)\n",
    "        df = transform_id_cod_to_string(df)\n",
    "        df = transformar_valores(df)\n",
    "        df = transformar_valores_float(df)\n",
    "#        df = converter_float64_to_int(df) \n",
    "        print(f\"Tratamento do {endpoint}.parquet concluído\")\n",
    "        enviar_parquet_azure(account_name, account_key, container_name_send, f'{endpoint}.parquet', df)\n",
    "        print(f\"Envio do {endpoint}.parquet concluído\")\n",
    "        \n",
    "# Usando a função para processar todos os endpoints\n",
    "processar_endpoints(account_name, account_key, container_name_read, container_name_send, endpoints)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
