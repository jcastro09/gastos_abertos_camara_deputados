{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ESSE SCRIPT TEM COMO OBJETIVO DE EXTRAIR TODOS OS DADOS DOS DEPUTADOS E DOS PARTIDOS CRIANDO ARQUIVO deputadosCompleto e partidosCompleto na bronze\n",
    "# \n",
    "# \n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import re\n",
    "import pyarrow as pa\n",
    "import io\n",
    "import os\n",
    "import pyarrow.parquet as pq\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
    "\n",
    "\n",
    "# Substitua pelos valores reais obtidos no Passo 1\n",
    "account_name = 'uvabr'\n",
    "account_key = os.environ['ACCOUNT_KEY']\n",
    "container_name = 'bronze'\n",
    "\n",
    "# Conecte-se ao serviço de armazenamento de blob\n",
    "connect_str = f\"DefaultEndpointsProtocol=https;AccountName={account_name};AccountKey={account_key};EndpointSuffix=core.windows.net\"\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
    "\n",
    "# Acesse o contêiner\n",
    "container_client = blob_service_client.get_container_client(container_name)\n",
    "\n",
    "\n",
    "# Função para extrair dados da API\n",
    "def extrair_dados_api(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data['dados']\n",
    "    else:\n",
    "        print(f\"Erro ao acessar a API: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Função para transformar dados em dataframe\n",
    "def transformar_dados_para_dataframe(dados):\n",
    "    df = pd.json_normalize(dados)\n",
    "    return df\n",
    "\n",
    "# Função para extrair dados das URIs em paralelo\n",
    "def extrair_dados_uris(uris):\n",
    "    dados_completos = []\n",
    "    contagem = 0\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        future_to_url = {executor.submit(extrair_dados_api, uri): uri for uri in uris}\n",
    "        for future in as_completed(future_to_url):\n",
    "            uri = future_to_url[future]\n",
    "            try:\n",
    "                dados_api = future.result()\n",
    "                if dados_api:\n",
    "                    dados_completos.append(dados_api)\n",
    "                contagem += 1\n",
    "                print(f\"Processando {contagem}: {uri}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao processar {uri}: {e}\")\n",
    "\n",
    "    if dados_completos:\n",
    "        df_completo = pd.json_normalize(dados_completos)\n",
    "        return df_completo\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "def enviar_parquet_azure(account_name, account_key, container_name_send, file_name, dataframe):\n",
    "    # Conecte-se ao serviço de armazenamento de blob\n",
    "    connect_str = f\"DefaultEndpointsProtocol=https;AccountName={account_name};AccountKey={account_key};EndpointSuffix=core.windows.net\"\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
    "\n",
    "    # Acesse o contêiner\n",
    "    container_client = blob_service_client.get_container_client(container_name_send)\n",
    "\n",
    "    # Converta DataFrame para tabela Parquet\n",
    "    table = pa.Table.from_pandas(dataframe)\n",
    "\n",
    "    # Crie um buffer de memória para escrever os dados Parquet\n",
    "    parquet_buffer = io.BytesIO()\n",
    "    pq.write_table(table, parquet_buffer)\n",
    "\n",
    "    # Envie os dados para o Azure Blob Storage\n",
    "    blob_client = container_client.get_blob_client(file_name)\n",
    "    blob_client.upload_blob(parquet_buffer.getvalue(), overwrite=True)\n",
    "\n",
    "    print(f\"Arquivo Parquet '{file_name}' enviado com sucesso para o Azure Blob Storage.\")\n",
    "\n",
    "def transformar_coluna_data(dfdata):\n",
    "    for coluna in dfdata.columns:\n",
    "        if 'data' in coluna.lower():  # Verifica se o nome da coluna contém 'data'\n",
    "            try:\n",
    "                dfdata[coluna] = dfdata[coluna].apply(lambda x: '' if (x == None or x < ('1800-01-01') or x > ('2099-12-31') ) else x)\n",
    "                dfdata[coluna] = pd.to_datetime(dfdata[coluna], errors='coerce')  # Converte para datetime\n",
    "            except ValueError:\n",
    "                print(f\"Erro ao converter coluna {coluna} para datetime.\")\n",
    "    return dfdata\n",
    "\n",
    "def transform_id_cod_to_string(df):\n",
    "    for coluna in df.columns:\n",
    "        if 'id' in coluna.lower() or 'cod' in coluna.lower():\n",
    "            df[coluna] = df[coluna].astype(str)\n",
    "    return df\n",
    "\n",
    "def transformar_valores(df):\n",
    "    for column in df.columns:\n",
    "        if 'url' not in column.lower():  # Verifica se \"url\" NÃO está no nome da coluna\n",
    "            if df[column].dtype != 'datetime64[ns]' and df[column].dtype != 'float64':\n",
    "                df[column] = df[column].replace(['', '<NA>', '[]', pd.NaT, np.nan, None], 'N/A')\n",
    "            elif df[column].dtype == 'float64':\n",
    "                print(\"nada funciona aqui\")\n",
    "                df[column] = df[column].fillna('N/A').astype('str')\n",
    "    return df\n",
    "\n",
    "def transformar_valores_float(df):\n",
    "    for column in df.columns:\n",
    "        if 'valor' in column.lower():\n",
    "            print(column)# Verifica se \"url\" NÃO está no nome da coluna\n",
    "            if df[column].dtype == 'object' or df[column].dtype == 'string':\n",
    "                df[column] = df[column].astype(float)\n",
    "                print(\"transformacao concluida com sucessso\")  \n",
    "            else:\n",
    "                print(\"Deu ruim\")             \n",
    "    return df\n",
    "\n",
    "def converter_float64_to_int(df):\n",
    "    float_cols = df.select_dtypes(include=['float64']).columns\n",
    "    df[float_cols] = df[float_cols].astype('int')\n",
    "    return df\n",
    "\n",
    "# Nova função para substituir pontos por sublinhados nos nomes das colunas\n",
    "def substituir_pontos_por_sublinhados(df):\n",
    "    df.columns = [col.replace('.', '_') for col in df.columns]\n",
    "    return df\n",
    "\n",
    "\n",
    "# URL para extrair dados iniciais dos deputados\n",
    "url = \"https://dadosabertos.camara.leg.br/arquivos/deputados/json/deputados.json\"\n",
    "dados = extrair_dados_api(url)\n",
    "df = transformar_dados_para_dataframe(dados)\n",
    "\n",
    "# Extrair dados das URIs dos deputados e criar o dataframe df_deputados\n",
    "deputados = extrair_dados_uris(df['uri'])\n",
    "\n",
    "deputados = substituir_pontos_por_sublinhados(deputados)\n",
    "deputados = transformar_coluna_data(deputados)\n",
    "deputados = transform_id_cod_to_string(deputados)\n",
    "deputados = transformar_valores(deputados)\n",
    "deputados = transformar_valores_float(deputados)\n",
    "\n",
    "enviar_parquet_azure(account_name, account_key, 'bronze', f'deputadosCompleto.parquet', deputados)\n",
    "enviar_parquet_azure(account_name, account_key, 'silver', f'deputadosCompleto.parquet', deputados)\n",
    "enviar_parquet_azure(account_name, account_key, 'gold', f'deputadosCompleto.parquet', deputados)\n",
    "\n",
    "# Remover duplicatas do campo 'ultimoStatus.uriPartido' em df_deputados\n",
    "uris_partidos_unicos = deputados['ultimoStatus_uriPartido'].drop_duplicates()\n",
    "\n",
    "# Extrair dados das URIs dos partidos e criar um novo dataframe\n",
    "partidos = extrair_dados_uris(uris_partidos_unicos)\n",
    "partidos = substituir_pontos_por_sublinhados(partidos)\n",
    "partidos = transformar_coluna_data(partidos)\n",
    "partidos = transform_id_cod_to_string(partidos)\n",
    "partidos = transformar_valores(partidos)\n",
    "partidos = transformar_valores_float(partidos)\n",
    "partidos=partidos[['id','sigla','nome','uri','urlLogo','status_lider_uri']]\n",
    "enviar_parquet_azure(account_name, account_key, 'bronze', f'partidosCompleto.parquet', partidos)\n",
    "enviar_parquet_azure(account_name, account_key, 'silver', f'partidosCompleto.parquet', partidos)\n",
    "enviar_parquet_azure(account_name, account_key, 'gold', f'partidosCompleto.parquet', partidos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
