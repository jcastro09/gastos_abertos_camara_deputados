{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import os\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
    "\n",
    "# Substitua pelos valores reais obtidos no Passo 1\n",
    "account_name = 'uvabr'\n",
    "account_key = os.environ['ACCOUNT_KEY']\n",
    "container_name = 'bronze'\n",
    "\n",
    "# Conecte-se ao serviço de armazenamento de blob\n",
    "connect_str = f\"DefaultEndpointsProtocol=https;AccountName={account_name};AccountKey={account_key};EndpointSuffix=core.windows.net\"\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
    "\n",
    "# Acesse o contêiner\n",
    "container_client = blob_service_client.get_container_client(container_name)\n",
    "\n",
    "# Lista de anos desejados\n",
    "anos = ['2019','2020','2021','2022', '2023', '2024']\n",
    "\n",
    "# Lista de endpoints\n",
    "endpoints = [\n",
    "#    \"proposicoes\",\n",
    "#    \"proposicoesTemas\",\n",
    "#    \"proposicoesAutores\",\n",
    "#    \"frentes\",\n",
    "#    \"frentesDeputados\",\n",
    "#    \"grupos\",\n",
    "#    \"gruposMembros\",\n",
    "#    \"gruposHistorico\",\n",
    "#    \"legislaturas\",\n",
    "#    \"legislaturasMesas\",\n",
    "#    \"orgaos\",\n",
    "#    \"orgaosDeputados\",\n",
    "    \"deputados\",\n",
    "#    \"deputadosOcupacoes\",\n",
    "#    \"deputadosProfissoes\",\n",
    "#    \"eventos\",\n",
    "#    \"eventosOrgaos\",\n",
    "#    \"eventosRequerimentos\",\n",
    "#    \"votacoes\",\n",
    "#    \"votacoesOrientacoes\",\n",
    "#    \"votacoesVotos\",\n",
    "#    \"votacoesObjetos\",\n",
    "#    \"votacoesProposicoes\",\n",
    "#    \"funcionarios\",\n",
    "#    \"licitacoes\",\n",
    "#    \"licitacoesContratos\",\n",
    "#    \"licitacoesItens\",\n",
    "#    \"licitacoesPedidos\",\n",
    "#    \"licitacoesPropostas\",\n",
    "#    \"tecadTermos\",\n",
    "#    \"tecadCategorias\"\n",
    "]\n",
    "\n",
    "# Lista de endpoints exceções\n",
    "endpointsExceptions = [\n",
    "#    \"frentes\",\n",
    "#    \"frentesDeputados\",\n",
    "#    \"grupos\",\n",
    "#    \"gruposMembros\",\n",
    "#    \"gruposHistorico\",\n",
    "#    \"legislaturas\",\n",
    "#    \"legislaturasMesas\",\n",
    "#    \"orgaos\",\n",
    "    \"deputados\",\n",
    "#    \"deputadosOcupacoes\",\n",
    "#    \"deputadosProfissoes\",\n",
    "#    \"funcionarios\",\n",
    "#    \"tecadTermos\",\n",
    "#    \"tecadCategorias\",\n",
    "#    \"orgaosDeputados\"\n",
    "]\n",
    "\n",
    "# Função para obter os dados de uma URL específica\n",
    "def obter_dados(url_completa):\n",
    "    try:\n",
    "        response = requests.get(url_completa)\n",
    "        response.raise_for_status()  # Isso irá lançar uma exceção se a requisição falhar\n",
    "        print(url_completa)\n",
    "        data = response.json()\n",
    "        return data.get('dados', [])\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Erro ao obter dados da URL {url_completa}: {e}\")\n",
    "        return []  # Retorna uma lista vazia em caso de erro\n",
    "\n",
    "# Iterando sobre cada endpoint\n",
    "for endpoint in endpoints:\n",
    "    formato = 'json'  # ou qualquer outro formato que você deseja\n",
    "    dados_concatenados = pd.DataFrame()\n",
    "    # Verificando se o endpoint requer iteração sobre os anos\n",
    "    if endpoint not in endpointsExceptions:\n",
    "        # Iterando sobre cada ano\n",
    "        for ano in anos:\n",
    "            url = f'http://dadosabertos.camara.leg.br/arquivos/{endpoint}/{formato}/{endpoint}-{ano}.{formato}'\n",
    "            dados_ano = obter_dados(url)\n",
    "            if dados_ano:\n",
    "                dados_ano = pd.json_normalize(dados_ano, max_level=1)\n",
    "                dados_concatenados = pd.concat([dados_concatenados, dados_ano], ignore_index=True)\n",
    "    elif endpoint == \"orgaosDeputados\":\n",
    "        # Tratamento especial para o endpoint \"orgaosDeputados\"\n",
    "        for legislatura in range(51, 58):  # Legislativas de 51 a 57\n",
    "            url = f'http://dadosabertos.camara.leg.br/arquivos/{endpoint}/{formato}/{endpoint}-L{legislatura}.{formato}'\n",
    "            dados_legislatura = obter_dados(url)\n",
    "            print(url)\n",
    "            if dados_legislatura:\n",
    "                dados_legislatura = pd.json_normalize(dados_legislatura, max_level=1)\n",
    "                dados_legislatura['legislatura'] = legislatura\n",
    "                dados_concatenados = pd.concat([dados_concatenados, dados_legislatura], ignore_index=True)\n",
    "    else:\n",
    "        # Tratamento para endpoints que não possuem ano\n",
    "        url = f'http://dadosabertos.camara.leg.br/arquivos/{endpoint}/{formato}/{endpoint}.{formato}'\n",
    "        dados_ano = obter_dados(url)\n",
    "        if dados_ano:\n",
    "            dados_ano = pd.json_normalize(dados_ano, max_level=1)\n",
    "            dados_concatenados = pd.concat([dados_concatenados, dados_ano], ignore_index=True)\n",
    "            \n",
    "    if not dados_concatenados.empty:\n",
    "            # Obtendo o nome de referência do arquivo Parquet\n",
    "        blob_name = f'{endpoint}.parquet'\n",
    "        # Convertendo DataFrame para bytes\n",
    "        parquet_bytes = dados_concatenados.to_parquet()\n",
    "        # Fazendo upload diretamente para o Blob Storage\n",
    "        container_client.upload_blob(name=blob_name, data=parquet_bytes, overwrite=True)\n",
    "        print(f'Dados salvos como {blob_name} no Blob Storage')\n",
    "    else:\n",
    "        print(f'Não foram obtidos dados para o endpoint: {endpoint}')\n",
    "        \n",
    "def extract_json_from_zip(zip_content):\n",
    "    with zipfile.ZipFile(io.BytesIO(zip_content)) as zip_ref:\n",
    "        # Procura o arquivo JSON dentro do zip\n",
    "        json_file = [f for f in zip_ref.namelist() if f.endswith('.json')][0]\n",
    "        \n",
    "        # Lê o conteúdo do arquivo JSON\n",
    "        json_content = zip_ref.read(json_file)\n",
    "        \n",
    "        return json_content\n",
    "\n",
    "def json_to_loads(json_content, parquet_file):\n",
    "    # Decodifica o conteúdo JSON em uma string\n",
    "    json_str = json_content.decode('utf-8')\n",
    "    \n",
    "    # Transformando em DataFrame\n",
    "    df = pd.DataFrame(json.loads(json_str)['dados'])\n",
    "    \n",
    "    # Retorna o DataFrame\n",
    "    return df\n",
    "\n",
    "def process_api_data(years):\n",
    "    # Lista para armazenar todos os DataFrames de todos os anos\n",
    "    all_dfs = []\n",
    "    \n",
    "    for year in years:\n",
    "        # URL da API da Câmara dos Deputados\n",
    "        api_url = f\"https://www.camara.leg.br/cotas/Ano-{year}.json.zip\"\n",
    "        \n",
    "        # Faz o download do arquivo zip da URL\n",
    "        response = requests.get(api_url)\n",
    "        \n",
    "        # Extrai o conteúdo do arquivo zip em memória\n",
    "        json_content = extract_json_from_zip(response.content)\n",
    "        # Converte o conteúdo JSON em DataFrame\n",
    "        df = json_to_loads(json_content, f\"Ano-{year}.parquet\")\n",
    "        # Adiciona o DataFrame à lista\n",
    "        all_dfs.append(df)\n",
    "    \n",
    "    # Concatena todos os DataFrames em um único DataFrame\n",
    "    combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    \n",
    "    # Salva o DataFrame combinado como um único arquivo Parquet\n",
    "    combined_df = combined_df.convert_dtypes()\n",
    "    #combined_df.to_parquet(f\"{diretorio_destino}/deputadosDespesas.parquet\")\n",
    "    blob_name = f'deputadosDespesas.parquet'\n",
    "    parquet_bytes = combined_df.to_parquet()\n",
    "    container_client.upload_blob(name=blob_name, data=parquet_bytes, overwrite=True)\n",
    "    print(\"Dados de todos os anos das despesasDeputados convertidos para Parquet no Blob Storage com sucesso!\")\n",
    "\n",
    "# Chama a função para processar os dados de todos os anos e salvar em um único arquivo Parquet\n",
    "process_api_data(anos)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
