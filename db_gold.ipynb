{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "import io\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Credenciais\n",
    "account_name = 'uvabr'\n",
    "account_key = os.environ['ACCOUNT_KEY']\n",
    "container_name_read = 'silver'\n",
    "container_name_send = 'gold'\n",
    "\n",
    "endpoints = [\n",
    "    \"deputadosDespesas\",\n",
    "    \"proposicoes\",\n",
    "    \"proposicoesTemas\",\n",
    "    \"proposicoesAutores\",\n",
    "    \"frentes\",\n",
    "    \"frentesDeputados\",\n",
    "    \"grupos\",\n",
    "    \"gruposMembros\",\n",
    "    \"gruposHistorico\",\n",
    "    \"legislaturas\",\n",
    "    \"legislaturasMesas\",\n",
    "    \"orgaos\",\n",
    "    \"orgaosDeputados\",\n",
    "    \"deputados\",\n",
    "    \"deputadosOcupacoes\",\n",
    "    \"deputadosProfissoes\",\n",
    "    \"eventos\",\n",
    "    \"eventosOrgaos\",\n",
    "    \"eventosRequerimentos\",\n",
    "    \"votacoes\",\n",
    "    \"votacoesOrientacoes\",\n",
    "    \"votacoesVotos\",\n",
    "    \"votacoesObjetos\",\n",
    "    \"votacoesProposicoes\",\n",
    "    \"funcionarios\",\n",
    "    \"licitacoes\",\n",
    "    \"licitacoesContratos\",\n",
    "    \"licitacoesItens\",\n",
    "    \"licitacoesPedidos\",\n",
    "    \"licitacoesPropostas\",\n",
    "    \"tecadTermos\",\n",
    "    \"tecadCategorias\"\n",
    "]\n",
    "\n",
    "def ler_parquet_azure(account_name, account_key, container_name_read, file_name):\n",
    "    # Conecte-se ao serviço de armazenamento de blob\n",
    "    connect_str = f\"DefaultEndpointsProtocol=https;AccountName={account_name};AccountKey={account_key};EndpointSuffix=core.windows.net\"\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
    "\n",
    "    # Acesse o contêiner\n",
    "    container_client = blob_service_client.get_container_client(container_name_read)\n",
    "\n",
    "    # Baixe o blob do Azure Blob Storage\n",
    "    blob_client = container_client.get_blob_client(file_name)\n",
    "    blob_data = blob_client.download_blob()\n",
    "    blob_stream = io.BytesIO()\n",
    "    blob_stream.write(blob_data.readall())\n",
    "\n",
    "    # Leia o arquivo Parquet usando pyarrow\n",
    "    parquet_table = pq.read_table(blob_stream)\n",
    "\n",
    "    # Converta para DataFrame do Pandas\n",
    "    df = parquet_table.to_pandas()\n",
    "\n",
    "    return df\n",
    "\n",
    "def enviar_parquet_azure(account_name, account_key, container_name_send, file_name, dataframe):\n",
    "    # Conecte-se ao serviço de armazenamento de blob\n",
    "    connect_str = f\"DefaultEndpointsProtocol=https;AccountName={account_name};AccountKey={account_key};EndpointSuffix=core.windows.net\"\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
    "\n",
    "    # Acesse o contêiner\n",
    "    container_client = blob_service_client.get_container_client(container_name_send)\n",
    "\n",
    "    # Converta DataFrame para tabela Parquet\n",
    "    table = pa.Table.from_pandas(dataframe)\n",
    "\n",
    "    # Crie um buffer de memória para escrever os dados Parquet\n",
    "    parquet_buffer = io.BytesIO()\n",
    "    pq.write_table(table, parquet_buffer)\n",
    "\n",
    "    # Envie os dados para o Azure Blob Storage\n",
    "    blob_client = container_client.get_blob_client(file_name)\n",
    "    blob_client.upload_blob(parquet_buffer.getvalue(), overwrite=True)\n",
    "\n",
    "    print(f\"Arquivo Parquet '{file_name}' enviado com sucesso para o Azure Blob Storage.\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leitura do deputadosDespesas.parquet\n",
      "Arquivo Parquet 'deputadosDespesas.parquet' enviado com sucesso para o Azure Blob Storage.\n",
      "envio do deputadosDespesas.parquet concluida\n",
      "Leitura do proposicoes.parquet\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m         enviar_parquet_azure(account_name, account_key, container_name_send, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m, df)\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menvio do \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.parquet concluida\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mprocessar_endpoints\u001b[49m\u001b[43m(\u001b[49m\u001b[43maccount_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccount_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontainer_name_read\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontainer_name_send\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoints\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m, in \u001b[0;36mprocessar_endpoints\u001b[1;34m(account_name, account_key, container_name_read, container_name_send, endpoints)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m endpoint \u001b[38;5;129;01min\u001b[39;00m endpoints:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLeitura do \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mler_parquet_azure\u001b[49m\u001b[43m(\u001b[49m\u001b[43maccount_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccount_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontainer_name_read\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mendpoint\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     enviar_parquet_azure(account_name, account_key, container_name_send, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m, df)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menvio do \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.parquet concluida\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 65\u001b[0m, in \u001b[0;36mler_parquet_azure\u001b[1;34m(account_name, account_key, container_name_read, file_name)\u001b[0m\n\u001b[0;32m     62\u001b[0m blob_stream\u001b[38;5;241m.\u001b[39mwrite(blob_data\u001b[38;5;241m.\u001b[39mreadall())\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Leia o arquivo Parquet usando pyarrow\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m parquet_table \u001b[38;5;241m=\u001b[39m \u001b[43mpq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_stream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Converta para DataFrame do Pandas\u001b[39;00m\n\u001b[0;32m     68\u001b[0m df \u001b[38;5;241m=\u001b[39m parquet_table\u001b[38;5;241m.\u001b[39mto_pandas()\n",
      "File \u001b[1;32mc:\\Users\\joaoc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyarrow\\parquet\\core.py:2986\u001b[0m, in \u001b[0;36mread_table\u001b[1;34m(source, columns, use_threads, metadata, schema, use_pandas_metadata, read_dictionary, memory_map, buffer_size, partitioning, filesystem, filters, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit)\u001b[0m\n\u001b[0;32m   2975\u001b[0m         \u001b[38;5;66;03m# TODO test that source is not a directory or a list\u001b[39;00m\n\u001b[0;32m   2976\u001b[0m         dataset \u001b[38;5;241m=\u001b[39m ParquetFile(\n\u001b[0;32m   2977\u001b[0m             source, metadata\u001b[38;5;241m=\u001b[39mmetadata, read_dictionary\u001b[38;5;241m=\u001b[39mread_dictionary,\n\u001b[0;32m   2978\u001b[0m             memory_map\u001b[38;5;241m=\u001b[39mmemory_map, buffer_size\u001b[38;5;241m=\u001b[39mbuffer_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2983\u001b[0m             thrift_container_size_limit\u001b[38;5;241m=\u001b[39mthrift_container_size_limit,\n\u001b[0;32m   2984\u001b[0m         )\n\u001b[1;32m-> 2986\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2987\u001b[0m \u001b[43m                        \u001b[49m\u001b[43muse_pandas_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_pandas_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2989\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2990\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_legacy_dataset=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to get the legacy behaviour is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2991\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated as of pyarrow 8.0.0, and the legacy implementation will \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2992\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbe removed in a future version.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2993\u001b[0m     \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m   2995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_prefixes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\joaoc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyarrow\\parquet\\core.py:2614\u001b[0m, in \u001b[0;36m_ParquetDatasetV2.read\u001b[1;34m(self, columns, use_threads, use_pandas_metadata)\u001b[0m\n\u001b[0;32m   2606\u001b[0m         index_columns \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   2607\u001b[0m             col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m _get_pandas_index_columns(metadata)\n\u001b[0;32m   2608\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, \u001b[38;5;28mdict\u001b[39m)\n\u001b[0;32m   2609\u001b[0m         ]\n\u001b[0;32m   2610\u001b[0m         columns \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2611\u001b[0m             \u001b[38;5;28mlist\u001b[39m(columns) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(index_columns) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(columns))\n\u001b[0;32m   2612\u001b[0m         )\n\u001b[1;32m-> 2614\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_filter_expression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2616\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_threads\u001b[49m\n\u001b[0;32m   2617\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2619\u001b[0m \u001b[38;5;66;03m# if use_pandas_metadata, restore the pandas metadata (which gets\u001b[39;00m\n\u001b[0;32m   2620\u001b[0m \u001b[38;5;66;03m# lost if doing a specific `columns` selection in to_table)\u001b[39;00m\n\u001b[0;32m   2621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_pandas_metadata:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def processar_endpoints(account_name, account_key, container_name_read, container_name_send, endpoints):\n",
    "    for endpoint in endpoints:\n",
    "        print(f\"Leitura do {endpoint}.parquet\")\n",
    "        df = ler_parquet_azure(account_name, account_key, container_name_read, f'{endpoint}.parquet')\n",
    "        enviar_parquet_azure(account_name, account_key, container_name_send, f'{endpoint}.parquet', df)\n",
    "        print(f\"envio do {endpoint}.parquet concluida\")\n",
    "        \n",
    "processar_endpoints(account_name, account_key, container_name_read, container_name_send, endpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "HttpResponseError",
     "evalue": "The specified account is disabled.\nRequestId:15f2c2f4-701e-006a-4025-b7a1ab000000\nTime:2024-06-05T08:48:56.1279445Z\nErrorCode:AccountIsDisabled\nContent: <?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>AccountIsDisabled</Code><Message>The specified account is disabled.\nRequestId:15f2c2f4-701e-006a-4025-b7a1ab000000\nTime:2024-06-05T08:48:56.1279445Z</Message></Error>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHttpResponseError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mler_parquet_azure\u001b[49m\u001b[43m(\u001b[49m\u001b[43maccount_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccount_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgold\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdeputadosDespesas.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mcount()\n",
      "Cell \u001b[1;32mIn[1], line 60\u001b[0m, in \u001b[0;36mler_parquet_azure\u001b[1;34m(account_name, account_key, container_name_read, file_name)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Baixe o blob do Azure Blob Storage\u001b[39;00m\n\u001b[0;32m     59\u001b[0m blob_client \u001b[38;5;241m=\u001b[39m container_client\u001b[38;5;241m.\u001b[39mget_blob_client(file_name)\n\u001b[1;32m---> 60\u001b[0m blob_data \u001b[38;5;241m=\u001b[39m \u001b[43mblob_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_blob\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m blob_stream \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO()\n\u001b[0;32m     62\u001b[0m blob_stream\u001b[38;5;241m.\u001b[39mwrite(blob_data\u001b[38;5;241m.\u001b[39mreadall())\n",
      "File \u001b[1;32mc:\\Users\\joaoc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\azure\\core\\tracing\\decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[1;32mc:\\Users\\joaoc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\azure\\storage\\blob\\_blob_client.py:942\u001b[0m, in \u001b[0;36mBlobClient.download_blob\u001b[1;34m(self, offset, length, encoding, **kwargs)\u001b[0m\n\u001b[0;32m    848\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Downloads a blob to the StorageStreamDownloader. The readall() method must\u001b[39;00m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;124;03mbe used to read all the content or readinto() must be used to download the blob into\u001b[39;00m\n\u001b[0;32m    850\u001b[0m \u001b[38;5;124;03ma stream. Using chunks() returns an iterator which allows the user to iterate over the content in chunks.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;124;03m        :caption: Download a blob.\u001b[39;00m\n\u001b[0;32m    936\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    937\u001b[0m options \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download_blob_options(\n\u001b[0;32m    938\u001b[0m     offset\u001b[38;5;241m=\u001b[39moffset,\n\u001b[0;32m    939\u001b[0m     length\u001b[38;5;241m=\u001b[39mlength,\n\u001b[0;32m    940\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m    941\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 942\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m StorageStreamDownloader(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32mc:\\Users\\joaoc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\azure\\storage\\blob\\_download.py:367\u001b[0m, in \u001b[0;36mStorageStreamDownloader.__init__\u001b[1;34m(self, clients, config, start_range, end_range, validate_content, encryption_options, max_concurrency, name, container, encoding, download_cls, **kwargs)\u001b[0m\n\u001b[0;32m    357\u001b[0m     initial_request_end \u001b[38;5;241m=\u001b[39m initial_request_start \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_first_get_size \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_range, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_offset \u001b[38;5;241m=\u001b[39m process_range_and_offset(\n\u001b[0;32m    360\u001b[0m     initial_request_start,\n\u001b[0;32m    361\u001b[0m     initial_request_end,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    364\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encryption_data\n\u001b[0;32m    365\u001b[0m )\n\u001b[1;32m--> 367\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initial_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproperties \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response\u001b[38;5;241m.\u001b[39mproperties\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproperties\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[1;32mc:\\Users\\joaoc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\azure\\storage\\blob\\_download.py:463\u001b[0m, in \u001b[0;36mStorageStreamDownloader._initial_request\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    461\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 463\u001b[0m         \u001b[43mprocess_storage_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\joaoc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\azure\\storage\\blob\\_shared\\response_handlers.py:184\u001b[0m, in \u001b[0;36mprocess_storage_error\u001b[1;34m(storage_error)\u001b[0m\n\u001b[0;32m    181\u001b[0m error\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m (error\u001b[38;5;241m.\u001b[39mmessage,)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;66;03m# `from None` prevents us from double printing the exception (suppresses generated layer error context)\u001b[39;00m\n\u001b[1;32m--> 184\u001b[0m     \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mraise error from None\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# pylint: disable=exec-used # nosec\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mSyntaxError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[1;32m<string>:1\u001b[0m\n",
      "\u001b[1;31mHttpResponseError\u001b[0m: The specified account is disabled.\nRequestId:15f2c2f4-701e-006a-4025-b7a1ab000000\nTime:2024-06-05T08:48:56.1279445Z\nErrorCode:AccountIsDisabled\nContent: <?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>AccountIsDisabled</Code><Message>The specified account is disabled.\nRequestId:15f2c2f4-701e-006a-4025-b7a1ab000000\nTime:2024-06-05T08:48:56.1279445Z</Message></Error>"
     ]
    }
   ],
   "source": [
    "df = ler_parquet_azure(account_name, account_key, 'gold', f'deputadosDespesas.parquet')\n",
    "df.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
